# NAS100 ML ê±°ë˜ ì‹œìŠ¤í…œ ê°œë°œ ë¡œë“œë§µ v4.0

## ğŸ›¡ï¸ ë™ì  ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì‹œìŠ¤í…œ
ìƒì¡´í™•ë¥  90% ì´ìƒì„ ìœ ì§€í•˜ë©° ì§€ì†ê°€ëŠ¥í•œ ì„±ì¥ì„ ì¶”êµ¬í•˜ëŠ” ì ì‘í˜• ML ê±°ë˜ ì‹œìŠ¤í…œ

## âš ï¸ ì¤‘ìš” ê²½ê³  ë° ë©´ì±…ì¡°í•­

### íˆ¬ì ìœ„í—˜ ê²½ê³ 
- **ì´ ì‹œìŠ¤í…œì€ ë†’ì€ ê¸ˆìœµ ë¦¬ìŠ¤í¬ë¥¼ í¬í•¨í•©ë‹ˆë‹¤**
- **ì „ì²´ íˆ¬ìê¸ˆ ì†ì‹¤ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤**
- **ë ˆë²„ë¦¬ì§€ ì‚¬ìš©ì€ ì†ì‹¤ì„ ì¦í­ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤**
- **ê³¼ê±° ì„±ê³¼ê°€ ë¯¸ë˜ ìˆ˜ìµì„ ë³´ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤**
- **ì‹¤ì œ ê±°ë˜ ì „ ì¶©ë¶„í•œ í…ŒìŠ¤íŠ¸ì™€ ê²€ì¦ì´ í•„ìˆ˜ì…ë‹ˆë‹¤**

### ë™ì  ë¦¬ìŠ¤í¬ ì „ëµ ê²½ê³ 
ì´ ë¡œë“œë§µì€ **ë¦¬ìŠ¤í¬%ì™€ ë ˆë²„ë¦¬ì§€ë¥¼ ë™ì ìœ¼ë¡œ ìµœì í™”**í•˜ëŠ” ì „ëµì…ë‹ˆë‹¤.
- ìƒì¡´í™•ë¥  90% ì´ìƒ ìœ ì§€í•˜ë©´ì„œ ìµœëŒ€ ìˆ˜ìµ ì¶”êµ¬
- Walk-Forwardë§ˆë‹¤ ìµœì  ë¦¬ìŠ¤í¬-ë ˆë²„ë¦¬ì§€ ì¡°í•© ì¬ê³„ì‚°
- ì‹œì¥ ìƒíƒœì— ë”°ë¼ ì¼ì¼ ì†ì‹¤ í•œë„ 5-25% ë³€ë™
- ëª©í‘œ: ë†’ì€ ìƒì¡´í™•ë¥ ë¡œ ì§€ì†ê°€ëŠ¥í•œ ì„±ì¥

## ğŸ“‹ v4.0 ê°œì„ ì‚¬í•­
- 2ë‹¨ê³„ ë¦¬ìŠ¤í¬-ë ˆë²„ë¦¬ì§€ ìµœì í™” (MC-Kelly â†’ Bayesian)
- Wilson interval ê¸°ë°˜ RoR ê³„ì‚°
- EWMA spread (50í‹±) Ã— 1.8 ê¸°ì¤€ ë”ë¸” ë ˆì§
- Walk-Forward ì„¤ê³„ ê°œì„  (6M-1M-1M, ìƒ˜í”Œìˆ˜ ë³´ì¥)
- ë¡¤ì˜¤ë²„ gap ë° ìŠ¤í”„ë ˆë“œ í™•ëŒ€ ë°˜ì˜
- ìƒì¡´í™•ë¥  ê¸°ë°˜ ì˜ì‚¬ê²°ì • (90% íƒ€ê²Ÿ)
- Volatility regimeë³„ ë™ì  ì„ê³„ê°’
- PCA previewë¡œ í”¼ì²˜ êµ°ì§‘ í™•ì¸
- Bidirectional LSTM + Attention ì˜µì…˜
- CatBoost ëŒ€ì•ˆ ëª¨ë¸ ì¶”ê°€
- Quantile-based ì§„ì… ê·œì¹™
- ìŠ¬ë¦¬í”¼ì§€ ëœë¤í™” ë°±í…ŒìŠ¤íŠ¸
- ì‹¤ì‹œê°„ ë°ì´í„° ì§€ì—° ê°ì§€

## ğŸ”‘ í•µì‹¬ ë³´ì™„ (P1 Priority)
1. **2ë‹¨ê³„ ë™ì  ë¦¬ìŠ¤í¬-ë ˆë²„ë¦¬ì§€ ìµœì í™”**
   - MC-Kellyë¡œ Risk 3ê°œ í›„ë³´ ì„ ë³„ (Low/Mid/High)
   - Bayesian optimizationìœ¼ë¡œ ë ˆë²„ë¦¬ì§€ ì—°ì† íƒìƒ‰
   - 8-10íšŒ í‰ê°€ë¡œ ìˆ˜ë ´ (ê¸°ì¡´ 50-60íšŒ â†’ ëŒ€í­ ë‹¨ì¶•)
   
2. **Wilson interval ê¸°ë°˜ RoR ê³„ì‚°**
   - ì†Œí‘œë³¸ í¸í–¥ ì™„í™”
   - MC ì…ë ¥: p(win), R:R, Risk%, #trades (4ê°œ ê³ ì •)
   - RoR < 10% ëª©í‘œ, > 30% ì‹œ ê±°ë˜ ì¤‘ë‹¨
   
3. **ë”ë¸” ë ˆì§ ëª¨ë¸ (ATR Ã— Spread)**
   - EWMA spread (50í‹±/5ë¶„) Ã— 1.8 = High Spread
   - 15ì´ˆë§ˆë‹¤ ì—…ë°ì´íŠ¸, ì§„ì… ì§ì „ ì¬í™•ì¸
   - High-vol + High-spread = ì§„ì… ê¸ˆì§€
   
4. **ë°ì´í„° í’ˆì§ˆ ê°•í™”**
   - Walk-Forward: 6M train â†’ 1M val â†’ 1M test
   - ìµœì†Œ ìƒ˜í”Œìˆ˜ ë³´ì¥ (train â‰¥ 20k, val/test â‰¥ 5k)
   - ë¡¤ì˜¤ë²„ gap ë°˜ì˜ ë° ì „í›„ 3ì¼ spread Ã— 1.3

## ğŸ¯ ëª©í‘œ
52-55% ì˜ˆì¸¡ ì •í™•ë„ë¡œ ì§€ì†ê°€ëŠ¥í•œ ì„±ì¥ì„ ë‹¬ì„±í•˜ëŠ” ë™ì  ML ì‹œìŠ¤í…œ
- ìƒì¡´í™•ë¥  ëª©í‘œ: > 90%
- Sharpe Ratio: > 0.8
- ë¦¬ìŠ¤í¬-ìˆ˜ìµ ìµœì í™”: Walk-Forwardë§ˆë‹¤ ì¬ê³„ì‚°
- ì‹œì¥ ì ì‘í˜• í¬ì§€ì…˜ ì‚¬ì´ì§•

---

## Phase 1: ë°ì´í„° ê²€ì¦ ë° ë¼ë²¨ë§ ì¬ì„¤ê³„

### 1.1 ë°ì´í„° í’ˆì§ˆ ì¬ê²€ì¦
```python
# ê¸°ì¡´ ë°ì´í„° íŒŒì¼ ì²´í¬
- ì‹œê°„ ê°­ í™•ì¸
- ì´ìƒì¹˜ ì œê±° (ì¼ì¼ 20% ì´ìƒ ë³€ë™ ë“±)
- ìŠ¤í”„ë ˆë“œ ë°ì´í„° ì •ìƒ ë²”ìœ„ í™•ì¸
```

### 1.2 Triple Barrier ë¼ë²¨ë§ êµ¬í˜„
```python
# ë™ì  ì„ê³„ê°’ ì„¤ì •
- Primary: ATR ê¸°ë°˜ threshold = 0.7 * ATR(20)
- Secondary: ê³ ì • threshold = 0.002 (0.2%) ë¹„êµ
- Volatility regimeë³„ ì¡°ì •:
  * Low vol (VIX<15): 0.5 * ATR
  * Normal (VIX 15-25): 0.7 * ATR  
  * High vol (VIX>25): 1.0 * ATR
- ì‹œê°„ í•œê³„: 4ë´‰(1ì‹œê°„), 8ë´‰(2ì‹œê°„) í…ŒìŠ¤íŠ¸
- ì¤‘ë¦½ ì¼€ì´ìŠ¤ëŠ” í•™ìŠµì—ì„œ ì œì™¸

# êµ¬í˜„ ì„¸ë¶€ì‚¬í•­
- TP/SL ë¹„ëŒ€ì¹­ í…ŒìŠ¤íŠ¸ 
  * ë³´ìˆ˜ì : TP=1.5*ATR, SL=1.0*ATR
  * ê· í˜•: TP=2.0*ATR, SL=1.0*ATR
  * ê³µê²©ì : TP=2.5*ATR, SL=1.0*ATR
- ì‹œê°„ëŒ€ë³„ ì„ê³„ê°’ ì¡°ì • ê°€ëŠ¥ì„± ê²€í† 
- ì£¼ë§/íœ´ì¼ ê²½ê³„ ì²˜ë¦¬
- ê·¹ë‹¨ì  ë³€ë™ì„± ì‹œ ì„ê³„ê°’ í™•ëŒ€

# ì˜ˆìƒ ê²°ê³¼
- í•™ìŠµ ìƒ˜í”Œ ìˆ˜: ê¸°ì¡´ ëŒ€ë¹„ 60-70%
- í´ë˜ìŠ¤ ë¶„í¬: 45:55 ~ 55:45 (ê· í˜•)
- ì¼í‰ê·  ë¼ë²¨: ìµœì í™” ê²°ê³¼ì— ë”°ë¼ ë³€ë™
```

### 1.3 íƒ€ê²Ÿ ê²€ì¦
```python
# ë¼ë²¨ ë¶„í¬ ë¶„ì„
- ì‹œê°„ëŒ€ë³„ ìŠ¹ë¥  íˆíŠ¸ë§µ
- ìš”ì¼ë³„ íŒ¨í„´ ë¶„ì„
- ë³€ë™ì„± êµ¬ê°„ë³„ ë¼ë²¨ ë¶„í¬
- Volatility regimeë³„ ìŠ¹ë¥  ì°¨ì´
- ì—°ì† ìŠ¹/íŒ¨ ë¶„ì„
```

---

## Phase 2: í•˜ì´ë¸Œë¦¬ë“œ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§

### 2.1 ì½”ì–´ í”¼ì²˜ ì„ ì • (17ê°œ ê³ ì •)
```python
# ê²€ì¦ëœ í•„ìˆ˜ í”¼ì²˜ - ë¬´ì¡°ê±´ í¬í•¨
1. ëª¨ë©˜í…€ (3ê°œ)
   - RSI(14)
   - ROC(10) 
   - MACD_signal
   
2. ë³€ë™ì„± (4ê°œ)
   - ATR_ratio (current/avg)
   - realized_vol_20
   - BB_width
   - volatility_regime (low/normal/high)
   
3. ë¯¸ì‹œêµ¬ì¡° (4ê°œ)
   - spread_ratio
   - spread_change_rate
   - high_low_ratio
   - spread_regime (high/normal)
   
4. ê°€ê²© ì•¡ì…˜ (3ê°œ)
   - price_position_in_range
   - MA20_deviation
   - candle_pattern_score
   
5. ì‹œê°„ (3ê°œ)
   - hour_sin/cos
   - session_progress
   - high_volatility_hour flag
   
6. MTF í™•ì¸ (2ê°œ)
   - H1_trend_direction
   - H4_support_resistance_distance
   
7. ì¶”ê°€ (1ê°œ)
   - consecutive_moves (ì—°ì† ìƒìŠ¹/í•˜ë½ ì¹´ìš´íŠ¸)
```

### 2.2 ì‹¤í—˜ í”¼ì²˜ í’€ (30ê°œ)
```python
# í†µê³„ì  ì„ íƒ ëŒ€ìƒ
1. ì¶”ê°€ ëª¨ë©˜í…€ ì§€í‘œ
   - Stochastic, Williams %R, CCI
   - ë‹¤ì–‘í•œ ê¸°ê°„ì˜ ROC
   
2. ë³µí•© ì§€í‘œ
   - RSI ë‹¤ì´ë²„ì „ìŠ¤
   - MACD íˆìŠ¤í† ê·¸ë¨ ë³€í™”ìœ¨
   
3. ê°€ê²© êµ¬ì¡°
   - ì¼ì¤‘ ê³ ì € ëŒ€ë¹„ í˜„ì¬ ìœ„ì¹˜
   - í”¼ë²— í¬ì¸íŠ¸ ê±°ë¦¬
   - ì´ì „ ê³ ì /ì €ì  ëŒíŒŒ
   - Donchian ì±„ë„ ìœ„ì¹˜
   
4. íŒ¨í„´ ì¸ì‹
   - ìº”ë“¤ íŒ¨í„´ variations
   - ì°¨íŠ¸ íŒ¨í„´ ì ìˆ˜
   - í”„ë™íƒˆ íŒ¨í„´
   
5. ì‹œì¥ ì²´ì œ
   - ADX variations
   - Choppiness Index
   - Hurst Exponent (ì¶”ì„¸ ê°•ë„)
   
6. í†µê³„ì  í”¼ì²˜
   - ìˆ˜ìµë¥  ì™œë„/ì²¨ë„
   - ìê¸°ìƒê´€ ì§€í‘œ
   - ì—”íŠ¸ë¡œí”¼ ì¸¡ì •
   - ì‹œê°„ëŒ€ë³„ í‰ê·  ë³€ë™ì„± ëŒ€ë¹„ í˜„ì¬
```

### 2.3 í”¼ì²˜ ì„ íƒ íŒŒì´í”„ë¼ì¸
```python
# Step 1: ìƒê´€ê´€ê³„ í•„í„° (|r| > 0.95 ì œê±°)
# Step 2: Variance Inflation Factor (VIF < 10)
# Step 3: PCA Preview (95% variance í™•ì¸)
# Step 4: Mutual Information ì ìˆ˜
# Step 5: Permutation Importance
# Step 6: ìµœì¢… 20-25ê°œ ì„ íƒ

# ê²€ì¦
- ê° ë‹¨ê³„ë³„ ì œê±° í”¼ì²˜ ê¸°ë¡
- PCA ê²°ê³¼ë¡œ í”¼ì²˜ êµ°ì§‘ í™•ì¸
- ìµœì¢… í”¼ì²˜ì˜ ì¹´í…Œê³ ë¦¬ë³„ ê· í˜• í™•ì¸
```

### 2.4 í”¼ì²˜ ì „ì²˜ë¦¬
```python
# ìŠ¤ì¼€ì¼ë§ ì „ëµ
- ê°€ê²© ê¸°ë°˜: RobustScaler
- ì§€í‘œ ê¸°ë°˜: MinMaxScaler(-1, 1)
- ì¹´í…Œê³ ë¦¬: One-hot or Ordinal
- ì‹œê°„: Cyclical encoding

# ê²°ì¸¡ì¹˜ ì²˜ë¦¬
- ì§€í‘œë³„ forward fill í•œê³„ ì„¤ì •
- ì´ˆê¸° ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì „ëµ

# ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€ í…ŒìŠ¤íŠ¸
- ê° í”¼ì²˜ ìƒì„± í›„ ìë™ ê²€ì¦
  ```python
  assert feature.shift(1).equals(feature_lagged)
  assert not feature.isna().all()
  assert feature.index.is_monotonic_increasing
  ```
- Look-ahead bias íƒì§€ ìœ ë‹› í…ŒìŠ¤íŠ¸
- í”¼ì²˜ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ ì¼ê´€ì„± ì²´í¬
```

---

## Phase 3: ëª¨ë¸ ê°œë°œ

### 3.1 ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸
```python
# ë‹¨ìˆœ ë¡œì§€ìŠ¤í‹± íšŒê·€
- ì½”ì–´ í”¼ì²˜ë§Œ ì‚¬ìš©
- ì„±ëŠ¥ í•˜í•œì„  ì„¤ì • (ëª©í‘œ: 51%+)
```

### 3.2 LSTM ì£¼ë ¥ ëª¨ë¸
```python
# ì•„í‚¤í…ì²˜
- Input: 30-50 timesteps
- LSTM layers: 2ê°œ (64, 32 units)
  * Option: Bidirectional LSTM
  * Option: Attention layer (8 heads)
- Dropout: 0.3
- Dense layers: 2ê°œ (16, 8)
- Output: Binary classification

# í•™ìŠµ ì „ëµ
- Learning rate: 0.001 â†’ 0.0001 (decay)
- Batch size: 128
- Early stopping: val_loss ê¸°ì¤€
- Gradient clipping: 1.0
```

### 3.3 íŠ¸ë¦¬ ê¸°ë°˜ ë³´ì¡° ëª¨ë¸
```python
# LightGBM
- ì „ì²´ í”¼ì²˜ í™œìš©
- í”¼ì²˜ ì¤‘ìš”ë„ ì¶”ì¶œìš©
- LSTMê³¼ ìƒê´€ê´€ê³„ ë‚®ì€ ì˜¤ë¥˜ íŒ¨í„´

# CatBoost (Alternative)
- ì¹´í…Œê³ ë¦¬ í”¼ì²˜ ìë™ ì²˜ë¦¬
- ì‘ì€ ë°ì´í„°ì…‹ì— ê°•ê±´
- Ordered boostingìœ¼ë¡œ ê³¼ì í•© ë°©ì§€

# í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
- Optuna 20 trials
- Time-series CV
```

### 3.4 ì•™ìƒë¸” ì „ëµ
```python
# Soft voting
- LSTM/BiLSTM: 0.5
- LightGBM/CatBoost: 0.3
- Baseline: 0.2

# ë™ì  ê°€ì¤‘ì¹˜
- ìµœê·¼ Nì¼ ì„±ëŠ¥ ê¸°ë°˜ ì¡°ì •
- Model confidence ê¸°ë°˜ ê°€ì¤‘
```

### 3.5 Walk-Forward ê²€ì¦
```python
# êµ¬ì¡° (ì¶©ë¶„í•œ ìƒ˜í”Œ í™•ë³´)
Train: 6ê°œì›” (â‰¥20k samples)
Gap: 1ì£¼ì¼  
Val: 1ê°œì›” (â‰¥5k samples)
Gap: 1ì£¼ì¼
Test: 1ê°œì›” (â‰¥5k samples)

# ë¡¤ë§ ìœˆë„ìš°
- 6ê°œì›” í•™ìŠµ â†’ 1ê°œì›” ê²€ì¦ â†’ 1ê°œì›” í…ŒìŠ¤íŠ¸
- 5íšŒ ë°˜ë³µ
- **ê° ìœˆë„ìš°ë§ˆë‹¤ ë¦¬ìŠ¤í¬-ë ˆë²„ë¦¬ì§€ ì¬ìµœì í™”**

# Expanding Window (ë¹„êµ ê²€ì¦)
- ì‹œì‘: 12ê°œì›”
- ë§¤ì›” ëˆ„ì  í•™ìŠµ
- ì¬í•™ìŠµ ì£¼ê¸° ê²°ì •ìš©

# Walk-Forward with ë™ì  ìµœì í™”
```python
def walk_forward_validation(data, model_class):
    windows = create_walk_forward_windows(
        data,
        train_months=6,
        val_months=1,
        test_months=1,
        gap_days=7
    )
    
    results = []
    for window in windows:
        # ìƒ˜í”Œ ìˆ˜ í™•ì¸
        assert len(window.train_data) >= 20000, "Train ìƒ˜í”Œ ë¶€ì¡±"
        assert len(window.val_data) >= 5000, "Val ìƒ˜í”Œ ë¶€ì¡±"
        
        # 1. ëª¨ë¸ í•™ìŠµ
        model = train_model(window.train_data, model_class)
        
        # 2. Validationì—ì„œ ë¦¬ìŠ¤í¬-ë ˆë²„ë¦¬ì§€ ìµœì í™”
        optimal_params = optimize_risk_leverage(
            window.val_data,
            model
        )
        
        # 3. Testì—ì„œ í‰ê°€
        test_results = evaluate_model(
            window.test_data,
            model,
            optimal_params
        )
        
        # 4. ê²°ê³¼ ì €ì¥
        results.append({
            'window_id': window.id,
            'optimal_params': optimal_params,
            'test_metrics': test_results
        })
        
        # 5. íŒŒë¼ë¯¸í„° ì €ì¥
        save_optimal_params(window.id, optimal_params)
    
    return results
```
```

---

## Phase 4: ê±°ë˜ ì „ëµ ìµœì í™”

### 4.1 ë¦¬ìŠ¤í¬-ë ˆë²„ë¦¬ì§€ ìŠ¤ìœ„íŠ¸ìŠ¤í¿ íƒìƒ‰ (2ë‹¨ê³„ ìµœì í™”)
```python
# Step 1: MC-Kellyë¡œ Risk êµ¬ê°„ 3ê°œ ì„ ë³„
def select_risk_candidates(historical_data):
    # ì´ˆê¸° í›„ë³´: Low, Mid, High
    risk_candidates = {
        'low': 0.5,    # ë³´ìˆ˜ì 
        'mid': 1.0,    # í‘œì¤€
        'high': 1.5    # ê³µê²©ì 
    }
    
    # Monte Carloë¡œ ê° Riskì˜ Kelly fraction ê³„ì‚°
    kelly_results = {}
    for risk_name, risk_pct in risk_candidates.items():
        kelly = monte_carlo_kelly(
            win_rate=0.52,  # ì˜ˆìƒ ìŠ¹ë¥ 
            risk_reward=1.5,  # R:R
            risk_pct=risk_pct,
            n_trades=250,    # ì—°ê°„ ê±°ë˜ìˆ˜
            n_iter=10000
        )
        kelly_results[risk_pct] = kelly
    
    # Kelly > 0.2ì¸ Riskë§Œ ì„ íƒ (ìµœëŒ€ 3ê°œ)
    selected_risks = [r for r, k in kelly_results.items() if k > 0.2]
    return sorted(selected_risks)[:3]

# Step 2: ì„ íƒëœ Riskì—ì„œ ë ˆë²„ë¦¬ì§€ ì—°ì† íƒìƒ‰ (Bayesian)
from skopt import gp_minimize

def optimize_leverage_for_risk(risk_pct, historical_data):
    def objective(leverage):
        # ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
        results = simulate_trading(
            historical_data,
            risk_pct,
            leverage[0]  # Bayesian optëŠ” ë¦¬ìŠ¤íŠ¸ë¡œ ì „ë‹¬
        )
        # ëª©í‘œ: Sharpe ìµœëŒ€í™” with ìƒì¡´í™•ë¥  ì œì•½
        if results['survival_rate'] < 0.9:
            return 10.0  # í˜ë„í‹°
        return -results['sharpe']  # ìµœì†Œí™” ë¬¸ì œë¡œ ë³€í™˜
    
    # Bayesian ìµœì í™” (8-10íšŒë©´ ìˆ˜ë ´)
    result = gp_minimize(
        func=objective,
        dimensions=[(5.0, 14.0)],  # ë ˆë²„ë¦¬ì§€ ë²”ìœ„
        n_calls=10,
        random_state=42
    )
    
    return result.x[0], -result.fun  # ìµœì  ë ˆë²„ë¦¬ì§€, Sharpe

# ì „ì²´ í”„ë¡œì„¸ìŠ¤
def optimize_risk_leverage(historical_data):
    # Step 1: Risk í›„ë³´ ì„ ë³„
    risk_candidates = select_risk_candidates(historical_data)
    
    # Step 2: ê° Riskë³„ ìµœì  ë ˆë²„ë¦¬ì§€ íƒìƒ‰
    results = {}
    for risk in risk_candidates:
        opt_lev, sharpe = optimize_leverage_for_risk(risk, historical_data)
        results[risk] = {
            'optimal_leverage': opt_lev,
            'sharpe': sharpe,
            'survival_rate': calculate_survival_rate(risk, opt_lev)
        }
    
    # ìµœì¢… ì„ íƒ (Sharpe ìµœëŒ€)
    best_risk = max(results.items(), key=lambda x: x[1]['sharpe'])
    
    # ê²°ê³¼ ì €ì¥
    with open('risk_profile.json', 'w') as f:
        json.dump({
            'optimal_risk_pct': best_risk[0],
            'optimal_leverage': best_risk[1]['optimal_leverage'],
            'metrics': best_risk[1]
        }, f)
    
    return best_risk
```

### 4.2 ì‹ í˜¸ ìƒì„±
```python
# í™•ë¥  ì„ê³„ê°’
- Fixed: P > 0.52 (ê³µê²©ì )
- Quantile-based: ìƒìœ„ X% (ë™ì )
  * ì¼ì¼ ì‹ í˜¸ ìˆ˜ ëª©í‘œ ê¸°ë°˜
  * í´ë˜ìŠ¤ ë¶ˆê· í˜• ìë™ ì¡°ì •
- Strong signal: P > 0.60 ë˜ëŠ” ìƒìœ„ 10%
- No trade zone: 0.48 < P < 0.52

# ë”ë¸” ë ˆì§ ì ìš©
```python
def get_entry_threshold(base_threshold, atr_regime, spread_regime):
    if spread_regime == 'high':
        # ìŠ¤í”„ë ˆë“œ ë†’ìœ¼ë©´ ë” ê°•í•œ ì‹ í˜¸ë§Œ
        return base_threshold + 0.05
    elif atr_regime == 'high' and spread_regime == 'high':
        return None  # ì§„ì… ê¸ˆì§€
    return base_threshold
```

# í•„í„°
- ë³€ë™ì„± í•„í„°: ATR > threshold
- ì‹œê°„ í•„í„° (ë¬´ë£Œ ëŒ€ì•ˆ)
  * ê³ ì • ê²½ì œì§€í‘œ ì‹œê°„ íšŒí”¼
    - 08:30 ET (ë¯¸êµ­ ê³ ìš©/CPI)
    - 10:00 ET (ë¯¸êµ­ ISM/ì†Œë¹„ìì‹ ë¢°)
    - 14:00 ET (FOMC ë°œí‘œì¼)
  * ê³¼ê±° ë°ì´í„° ë¶„ì„ìœ¼ë¡œ ì°¾ì€ ê³ ë³€ë™ ì‹œê°„ëŒ€
  * ì¥ ì‹œì‘/ë§ˆê° 30ë¶„
- ì„¸ì…˜ í•„í„°: ì£¼ìš” ì‹œì¥ ì‹œê°„
- ìŠ¤í”„ë ˆë“œ í•„í„°: spread > 2*avg_spread ì‹œ íšŒí”¼

# ë”ë¸” ë ˆì§ ëª¨ë¸ (ATR Ã— Spread)
- Normal ATR + Normal Spread: ì •ìƒ ì§„ì…
- High ATR + Normal Spread: TP/SL í™•ëŒ€
- Normal ATR + High Spread: ì‹ í˜¸ ê°•ë„ ìƒí–¥
- High ATR + High Spread: ì§„ì… ê¸ˆì§€

# Spread Regime íŒì • ê¸°ì¤€
```python
def calculate_spread_regime(current_spread, window=50):
    """
    EWMA ê¸°ë°˜ Spread Regime íŒì •
    - window: 50í‹± (ë˜ëŠ” 5ë¶„)
    - High threshold: EWMA Ã— 1.8
    """
    # EWMA ê³„ì‚° (alpha=2/(window+1))
    ewma_spread = current_spread_series.ewm(
        span=window, 
        adjust=False
    ).mean()
    
    # í˜„ì¬ ìŠ¤í”„ë ˆë“œê°€ EWMAì˜ 1.8ë°° ì´ˆê³¼ ì‹œ High
    if current_spread > ewma_spread.iloc[-1] * 1.8:
        return 'high'
    else:
        return 'normal'

# 15ì´ˆë§ˆë‹¤ ì—…ë°ì´íŠ¸, ì§„ì… ì§ì „ ì¬í™•ì¸
def check_entry_conditions():
    # ì§„ì… ì „ ìµœì¢… ì²´í¬ (Fail-Safe)
    current_spread = get_current_spread()
    spread_regime = calculate_spread_regime(current_spread)
    atr_regime = calculate_atr_regime()
    
    if spread_regime == 'high' and atr_regime == 'high':
        return False  # ì§„ì… ê¸ˆì§€
    
    return True
```
```

### 4.3 í¬ì§€ì…˜ ì‚¬ì´ì§•
```python
# ìµœì í™”ëœ íŒŒë¼ë¯¸í„° ë¡œë“œ
with open('risk_profile.json', 'r') as f:
    optimal_params = json.load(f)

# ë™ì  Risk-Leverage ì ìš©
base_risk_pct = optimal_params['optimal_risk_pct']
base_leverage = optimal_params['optimal_leverage']

# Kelly Criterion ë³€í˜•
kelly_fraction_dynamic = base_kelly * (1 - DD_ratio)
position_size = account * base_risk_pct * min(
    kelly_fraction_dynamic,
    confidence_score,
    volatility_adjustment
)

# Volatility regime ì¡°ì •
- Low vol: size Ã— 1.5
- Normal: size Ã— 1.0
- High vol: size Ã— 0.7

# ì‹¤ì§ˆ ë ˆë²„ë¦¬ì§€ ì œí•œ
actual_leverage = position_size / (stop_distance * pip_value)
if actual_leverage > base_leverage:
    position_size = base_leverage * stop_distance * pip_value

# ì œì•½ì‚¬í•­
- ìµœì†Œ: 0.01 lot
- ìµœëŒ€: ê³„ì •ì˜ 20%
- ë‹¨ê³„ì  ì¦ê°€
```

### 4.4 ë¦¬ìŠ¤í¬ ê´€ë¦¬
```python
# ê³„ì¢Œ ìˆ˜ì¤€ (ë™ì  ì¡°ì •)
- Daily loss limit: ìµœì í™”ëœ risk% Ã— ì—°ì†ì†ì‹¤ìˆ˜
- Weekly loss limit: ì‹œë®¬ë ˆì´ì…˜ ê¸°ë°˜ ì„¤ì •
- Max positions: 3-4
- Correlation check
- í¬ì§€ì…˜ê°„ ìƒê´€ê³„ìˆ˜ < 0.7

# ë™ì  ë¦¬ìŠ¤í¬ í…Œì´ë¸”
```python
def get_risk_parameters(vol_regime, dd_level, mc_results):
    base_risk = mc_results['optimal_risk_pct']
    base_lev = mc_results['optimal_leverage']
    
    # ì‹œì¥ ìƒíƒœë³„ ì¡°ì •
    if vol_regime == 'high' or dd_level > 15:
        return base_risk * 0.6, base_lev * 0.5
    elif vol_regime == 'low' and dd_level < 5:
        return base_risk * 1.1, base_lev * 1.2
    else:
        return base_risk, base_lev
```

# ë©€í‹°í¬ì§€ì…˜ ê´€ë¦¬
- ë™ì¼ ë°©í–¥ ìµœëŒ€ 2ê°œ
- ë°˜ëŒ€ ë°©í–¥ í—¤ì§• í—ˆìš©
- ì§„ì… ê°„ê²© ìµœì†Œ 15ë¶„
- ì „ì²´ ë…¸ì¶œë„: ë™ì  ê³„ì‚°

# í¬ì§€ì…˜ ìˆ˜ì¤€
- Stop Loss: 0.7 * ATR (ê¸°ë³¸)
- Take Profit: 1.4 * ATR (2:1)

# ë”ë¸” ë ˆì§ ì¡°ì •
```python
def adjust_tp_sl(base_tp, base_sl, atr_regime, spread_regime):
    if atr_regime == 'high' and spread_regime == 'normal':
        return base_tp * 1.3, base_sl * 1.2
    elif atr_regime == 'normal' and spread_regime == 'high':
        return base_tp * 1.1, base_sl  # TPë§Œ í™•ëŒ€
    elif atr_regime == 'high' and spread_regime == 'high':
        return None, None  # ì§„ì… ê¸ˆì§€
    else:
        return base_tp, base_sl
```

- Time stop: 2ì‹œê°„
- Trailing stop: 50% ì´ìµ í›„
```

### 4.5 ë¨¸ë‹ˆ ë§¤ë‹ˆì§€ë¨¼íŠ¸
```python
# ë³µë¦¬ ì „ëµ
- ìˆ˜ìµ 50% ì¶œê¸ˆ
- ë‚˜ë¨¸ì§€ 50% ì¬íˆ¬ì
- ì›ê¸ˆ 2ë°° ë„ë‹¬ ì‹œ ì›ê¸ˆ íšŒìˆ˜

# ì†ì‹¤ ë³µêµ¬ ì „ëµ (ë™ì )
def adjust_position_by_dd(current_dd, optimal_params):
    if current_dd > optimal_params['max_dd'] * 0.8:
        return "MIN_LOT"
    elif current_dd > optimal_params['max_dd'] * 0.5:
        return "HALF_SIZE"
    else:
        return "NORMAL"

# RoR ê¸°ë°˜ ë™ì  ì¡°ì •
def adjust_risk_by_ror(account_balance, mc_simulation):
    ror = mc_simulation.get_risk_of_ruin()
    if ror > 0.4:
        return "STOP_TRADING"
    elif ror > 0.3:
        return "MIN_LOT_ONLY"
    elif ror > 0.2:
        return "HALF_POSITION"
    else:
        return "NORMAL"

# Walk-Forward ì¬ìµœì í™” íŠ¸ë¦¬ê±°
- ìƒì¡´í™•ë¥  < 90%
- 3ê°œì›” ì—°ì† ëª©í‘œ ë¯¸ë‹¬ì„±
- ì‹œì¥ ë ˆì§ ê¸‰ë³€
```

---

## Phase 5: ë°±í…ŒìŠ¤íŠ¸ ë° ê²€ì¦

### 5.1 ë°±í…ŒìŠ¤íŠ¸ í™˜ê²½
```python
# í˜„ì‹¤ì  ê°€ì •
- Spread: ì‹¤ì œ ë°ì´í„° (tick)
- Slippage: 
  * Fixed: 0.5-1.0 pip
  * Random: Normal(Î¼=0.7, Ïƒ=0.2) pip
  * ë”ë¸” ë ˆì§ ì¡°ì •:
    - Normal: Î¼=0.7
    - High ATR: Î¼=1.2
    - High Spread: Î¼=1.5
    - Both High: Î¼=2.0
- Commission: $7/lot RT
- Margin call: 50%

# ë¡¤ì˜¤ë²„ ì²˜ë¦¬ (NAS100 CFD/ì„ ë¬¼)
```python
def apply_rollover_gaps(price_data, rollover_dates):
    """
    ë¶„ê¸°ë³„ ë¡¤ì˜¤ë²„ gap ë°˜ì˜
    - ë¡¤ì˜¤ë²„ ë‚ ì§œ: 3ì›”, 6ì›”, 9ì›”, 12ì›” ì…‹ì§¸ ê¸ˆìš”ì¼
    - Gap: ì „ì¼ ì¢…ê°€ - ì‹ ê·œ ì‹œê°€
    """
    for date in rollover_dates:
        if date in price_data.index:
            # ì „ì¼ ì¢…ê°€ì™€ ë‹¹ì¼ ì‹œê°€ì˜ gap
            prev_close = price_data.loc[:date].iloc[-2]['Close']
            curr_open = price_data.loc[date]['Open']
            gap = curr_open - prev_close
            
            # Gap ì ìš©
            price_data.loc[date:, ['Open', 'High', 'Low', 'Close']] += gap
            
            # ë¡¤ì˜¤ë²„ ì „í›„ 3ì¼ê°„ ìŠ¤í”„ë ˆë“œ í™•ëŒ€
            start_date = date - pd.Timedelta(days=3)
            end_date = date + pd.Timedelta(days=3)
            mask = (price_data.index >= start_date) & (price_data.index <= end_date)
            price_data.loc[mask, 'Spread'] *= 1.3
    
    return price_data
```

# ì œì•½ì‚¬í•­
- ê³ ì • ì‹œê°„ëŒ€ í•„í„° (ê²½ì œì§€í‘œ ì‹œê°„)
- ì£¼ë§ í¬ì§€ì…˜ ì •ë¦¬
- ê°­ ì˜¤í”ˆ ì²˜ë¦¬
- ì‹œê°„ëŒ€ë³„ ìŠ¬ë¦¬í”¼ì§€ ì°¨ë“± ì ìš©
- ë¡¤ì˜¤ë²„ ê¸°ê°„ ìŠ¤í”„ë ˆë“œ í™•ëŒ€
```

### 5.2 ì„±ê³¼ ì§€í‘œ
```python
# Primary Metrics
- Survival Rate: > 90%
- Sharpe Ratio: > 0.8
- Risk of Ruin: < 10%
- Win Rate: > 45%
- Profit Factor: > 1.3

# Secondary Metrics  
- Average Win/Loss ratio
- Consecutive losses (ìµœëŒ€ í—ˆìš©ì¹˜ ë™ì )
- Recovery time
- Monthly consistency
- Risk of Ruin ë¶„ì„
```

### 5.3 ìµœì í™” ê²€ì¦
```python
# ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¡œ ìµœì í™” íŒŒë¼ë¯¸í„° ê²€ì¦
optimal_params = json.load(open('risk_profile.json'))

# ì‹¤ì œ ì„±ê³¼ vs ì˜ˆìƒ ì„±ê³¼ ë¹„êµ
actual_metrics = {
    'sharpe': backtest_results['sharpe'],
    'max_dd': backtest_results['max_dd'],
    'survival_rate': 1 - backtest_results['ruin_prob']
}

expected_metrics = optimal_params['metrics']

# ê´´ë¦¬ë„ ë¶„ì„
deviation = {
    k: abs(actual_metrics[k] - expected_metrics[k]) / expected_metrics[k]
    for k in actual_metrics
}

# ì¬ìµœì í™” í•„ìš” ì—¬ë¶€ íŒë‹¨
if any(dev > 0.2 for dev in deviation.values()):
    print("ì¬ìµœì í™” í•„ìš”: ì‹¤ì œì™€ ì˜ˆìƒ ì„±ê³¼ ê´´ë¦¬ 20% ì´ˆê³¼")
    # Phase 4.1 ì¬ì‹¤í–‰
```

### 5.4 ê·¹ë‹¨ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
```python
# Stress Testing
- ì—°ì† 8íŒ¨ ì‹œë‚˜ë¦¬ì˜¤
- Flash crash ì‹œë®¬ë ˆì´ì…˜
- ìŠ¤í”„ë ˆë“œ 10ë°° í™•ëŒ€
- ìŠ¬ë¦¬í”¼ì§€ 5 pip

# Monte Carlo (Wilson interval ê¸°ë°˜ RoR)
- 10,000íšŒ ì‹œë®¬ë ˆì´ì…˜
- Risk of Ruin ê³„ì‚°
  * ëª©í‘œ: < 10%
  * ê²½ê³ : > 20%
  * ì¤‘ë‹¨: > 30%
- ìƒì¡´ìœ¨ ë¶„ì„
- ìµœì•… ì‹œë‚˜ë¦¬ì˜¤ ëŒ€ë¹„

# RoR ê³„ì‚° (Wilson interval)
```python
from scipy import stats
from statsmodels.stats.proportion import proportion_confint

def calculate_risk_of_ruin(win_rate, risk_reward, risk_pct, n_trades):
    """
    Wilson interval ê¸°ë°˜ RoR ê³„ì‚°
    ì…ë ¥: p(win), R:R, Risk%, ê±°ë˜ìˆ˜
    """
    # Wilson intervalë¡œ ìŠ¹ë¥  ì‹ ë¢°êµ¬ê°„ ê³„ì‚°
    n_wins = int(win_rate * n_trades)
    ci_low, ci_high = proportion_confint(n_wins, n_trades, 
                                        method='wilson',
                                        alpha=0.05)
    
    # ë³´ìˆ˜ì  ìŠ¹ë¥  ì‚¬ìš© (í•˜í•œ)
    p_conservative = ci_low
    
    # Kelly criterion
    kelly = (p_conservative * risk_reward - (1 - p_conservative)) / risk_reward
    
    # Risk of Ruin ê³µì‹
    if kelly <= 0:
        return 1.0  # 100% íŒŒì‚°
    
    # ë‹¨ìˆœí™”ëœ RoR (ë¬´í•œ ìë³¸ ê°€ì •)
    q = (1 - p_conservative) / p_conservative
    ror = q ** (1 / (risk_pct * kelly))
    
    return min(ror, 1.0)

def kelly_fraction_dynamic(base_kelly, mc_results):
    ruin_prob = mc_results['risk_of_ruin']
    dd_ratio = mc_results['current_dd'] / mc_results['max_dd']
    
    # RoR ê¸°ë°˜ Kelly ì¡°ì •
    if ruin_prob > 0.3:
        return 0  # ê±°ë˜ ì¤‘ë‹¨
    elif ruin_prob > 0.2:
        kelly = base_kelly * 0.5
    elif ruin_prob > 0.1:
        kelly = base_kelly * 0.7
    else:
        kelly = base_kelly * (1 - dd_ratio)
    
    return max(kelly, 0.01)  # ìµœì†Œê°’ ë³´ì¥
```
```

### 5.5 ìµœì í™” ê·¸ë¦¬ë“œ ì‹œê°í™”
```python
# 2D ë¦¬ìŠ¤í¬-ë ˆë²„ë¦¬ì§€ íˆíŠ¸ë§µ ìƒì„±
risk_lev_heatmap = pd.DataFrame(
    index=risk_grid,
    columns=lev_grid
)

for r, l in itertools.product(risk_grid, lev_grid):
    survival, sharpe, cagr = results[(r, l)]
    # Pareto ìµœì í•´ ì°¾ê¸°
    if survival > 0.9:
        risk_lev_heatmap.loc[r, l] = sharpe
    else:
        risk_lev_heatmap.loc[r, l] = np.nan

# ìµœì  ì˜ì—­ ì‹œê°í™”
plt.figure(figsize=(10, 8))
sns.heatmap(risk_lev_heatmap, 
            annot=True, 
            cmap='RdYlGn',
            center=0.8)
plt.title('Risk-Leverage Sweet Spot (Sharpe Ratio)')
plt.xlabel('Leverage')
plt.ylabel('Risk %')

# ë™ì  ì—…ë°ì´íŠ¸ ì €ì¥
optimal_params = {
    'timestamp': datetime.now(),
    'market_regime': current_regime,
    'optimal_risk': best_risk,
    'optimal_leverage': best_lev,
    'expected_sharpe': best_sharpe,
    'survival_rate': best_survival
}
```

### 5.6 íŒŒë¼ë¯¸í„° ë²”ìœ„
```python
# 2ë‹¨ê³„ ìµœì í™” íŒŒë¼ë¯¸í„°
# Step 1: MC-Kelly Risk ì„ ë³„
- Risk % í›„ë³´: [0.5, 1.0, 1.5] (Low, Mid, High)
- MC ì‹œë®¬ë ˆì´ì…˜: 10,000íšŒ
- Kelly > 0.2 í•„í„°

# Step 2: Bayesian ë ˆë²„ë¦¬ì§€ íƒìƒ‰
- Leverage ë²”ìœ„: [5.0, 14.0] (ì—°ì†)
- Bayesian calls: 8-10íšŒ
- ìˆ˜ë ´ ê¸°ì¤€: Sharpe ê°œì„  < 1%

# ê¸°íƒ€ íŒŒë¼ë¯¸í„°
- ATR multiplier (SL): [0.5, 0.7, 1.0]
- ATR multiplier (TP): [1.5, 2.0, 2.5]
- Time stop: [1h, 2h, 3h]

# ìµœì í™” ì œì•½ì¡°ê±´
- ìƒì¡´í™•ë¥  > 90% (Wilson interval ê¸°ë°˜)
- Sharpe Ratio > 0.8
- Max DD < 40%
- Risk of Ruin < 10%

# ëª©ì í•¨ìˆ˜ (ë‹¤ëª©ì  ìµœì í™”)
- Primary: ìƒì¡´í™•ë¥  ìµœëŒ€í™”
- Secondary: Sharpe Ratio ìµœëŒ€í™”
- Constraint: RoR < 10% (hard constraint)

# í‰ê·  ì‹¤í–‰ ì‹œê°„
- ì „ì²´ ìµœì í™”: 30-45ë¶„ (ê¸°ì¡´ 3-4ì‹œê°„ â†’ ëŒ€í­ ë‹¨ì¶•)
- Walk-Forward 1íšŒ: 6-8ë¶„
```

---

## Phase 6: ì‹¤ì „ ì „í™˜

### 6.1 ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜
```python
# ì‹¤ì‹œê°„ íŒŒì´í”„ë¼ì¸
1. Data Collection (1ë¶„ ì£¼ê¸°)
   - Price feed
   - Spread monitoring
   - Latency check (>5s alert)
   
2. Risk Parameter Loading
   - risk_profile.json ì½ê¸°
   - í˜„ì¬ ì‹œì¥ ìƒíƒœ í™•ì¸
   - ë™ì  íŒŒë¼ë¯¸í„° ì ìš©
   
3. Feature Pipeline  
   - ì½”ì–´ í”¼ì²˜ ê³„ì‚°
   - í”¼ì²˜ í’ˆì§ˆ ì²´í¬
   - Staleness detection
   
4. Prediction
   - ëª¨ë¸ ì•™ìƒë¸”
   - Confidence ê³„ì‚°
   - ë”ë¸” ë ˆì§ ì²´í¬
   
5. Execution
   - Signal validation
   - Order management
   - TP/SL ë™ì  ì¡°ì •
   
6. Monitoring
   - Performance tracking
   - Anomaly detection
   - Data freshness alerts
   - ìƒì¡´í™•ë¥  ì‹¤ì‹œê°„ ê³„ì‚°
   
7. Alert System
   - ìƒì¡´í™•ë¥  < 85% ê²½ê³ 
   - ì—°ì† ì†ì‹¤ ê²½ê³ 
   - ì‹œìŠ¤í…œ ì˜¤ë¥˜ ì¦‰ì‹œ ì•Œë¦¼
   - í¬ì§€ì…˜ ì²­ì‚° ì•Œë¦¼
```

### 6.2 ë‹¨ê³„ë³„ ì‹¤ì „ ì „í™˜
```python
# ì´ˆê¸° ìê¸ˆ: $300 (ì „ì•¡ ì†ì‹¤ ê°€ëŠ¥ ê¸ˆì•¡)
# ëª©í‘œ: ì§€ì†ê°€ëŠ¥í•œ ì„±ì¥ (ìƒì¡´í™•ë¥  > 90%)

# Week 1-2: Paper Trading
- Full system test
- Latency measurement
- Bug fixes
- ìµœëŒ€ ì†ì‹¤ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸

# Week 3-4: Micro lots (0.01)
- Real money psychology
- Slippage analysis
- ì—°ì† ì†ì‹¤ ëŒ€ì‘ í›ˆë ¨

# Week 5-8: Mini lots (0.1)  
- Scale test
- Risk metrics validation
- íšŒë³µ ì „ëµ ê²€ì¦

# Week 9+: Standard lots
- Gradual increase
- Performance monitoring
- ì‹¬ë¦¬ì  ì••ë°• ê´€ë¦¬
```

---

## ğŸ“Š ì˜ˆìƒ ì„±ê³¼ ì§€í‘œ

### ëª¨ë¸ ì„±ëŠ¥
```python
# ì˜ˆì¸¡ ì •í™•ë„
- Training: 54-56%
- Validation: 52-54%
- Test: 52-53%
- Gap < 2%

# ì‹ í˜¸ í’ˆì§ˆ
- Daily signals: ìµœì í™” ê²°ê³¼ì— ë”°ë¼ ë³€ë™
- High confidence (>0.6): ìƒìœ„ 10-20%
- Average holding: 45-90ë¶„
```

### ê±°ë˜ ì„±ê³¼
```python
# Returns (ì‹œë®¬ë ˆì´ì…˜ ê¸°ë°˜)
- Monthly: ìµœì í™” ê²°ê³¼ì— ë”°ë¦„
- Annual: ìƒì¡´í™•ë¥  90% ì œì•½ í•˜ ìµœëŒ€ê°’
- Sharpe: 0.8-1.5 (íƒ€ê²Ÿ)

# Risk (ë™ì  ê³„ì‚°)
- Max DD: ì‹œë®¬ë ˆì´ì…˜ 95% ì‹ ë¢°êµ¬ê°„
- Daily VaR: ìµœì  risk% ê¸°ë°˜
- Loss months: 30-40%

# ê±°ë˜ í”„ë¡œí•„ (ìµœì í™” ê²°ê³¼ ê¸°ë°˜)
- ì¼ í‰ê· : ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼
- í‰ê·  ë³´ìœ : 45-90ë¶„
- ìŠ¹ë¥ : 45-52%
- ì†ìµë¹„: ìµœì í™”ëœ R:R
```

---

## ğŸš¨ ë¦¬ìŠ¤í¬ ë° ì¤‘ë‹¨ ì‹ í˜¸

### Phase Gates
```python
# Phase 1-2
â–¡ Triple Barrier êµ¬í˜„ ì™„ë£Œ
â–¡ Volatility regimeë³„ ì„ê³„ê°’ ê²€ì¦
â–¡ í”¼ì²˜ 20-25ê°œë¡œ ì¶•ì†Œ
â–¡ PCA 95% variance í™•ì¸
â–¡ í´ë˜ìŠ¤ ê· í˜• ë‹¬ì„±
â–¡ ê³ ìœ„í—˜ ë¼ë²¨ ë¹„ìœ¨ í™•ì¸
â–¡ ë°ì´í„° ëˆ„ìˆ˜ í…ŒìŠ¤íŠ¸ ìœ ë‹› êµ¬í˜„

# Phase 3-4  
â–¡ Val accuracy > 52%
â–¡ Overfit gap < 3%
â–¡ Feature importance ë¶„ì„
â–¡ Attention weights í•´ì„ (BiLSTM)
â–¡ ë¦¬ìŠ¤í¬-ë ˆë²„ë¦¬ì§€ ìµœì í™” ì™„ë£Œ
â–¡ ìƒì¡´í™•ë¥  > 90% í™•ì¸
â–¡ Quantile threshold ìµœì í™”
â–¡ í”¼ì²˜ ìƒì„± ëˆ„ìˆ˜ ê²€ì¦ í†µê³¼

# Phase 5-6
â–¡ Risk-Leverage ìµœì í™” ì™„ë£Œ
â–¡ ìƒì¡´í™•ë¥  > 90% ë‹¬ì„±
â–¡ Backtest Sharpe > 0.8
â–¡ Paper-Real gap < 15%
â–¡ System stability 72h
â–¡ Data latency < 5s ìœ ì§€ìœ¨ 99%
â–¡ Risk-of-Ruin < 10%
â–¡ Kelly dynamic ì¡°ì • ê²€ì¦
â–¡ ë™ì  íŒŒë¼ë¯¸í„° ì‹¤ì‹œê°„ ì ìš©
```

### Red Flags
1. **Accuracy < 51%**: ë¼ë²¨/í”¼ì²˜ ì¬ê²€í† 
2. **í”¼ì²˜ > 30ê°œ**: ê³¼ì í•© ìœ„í—˜
3. **DD > ìµœì í™”ëœ í•œê³„**: ë¦¬ìŠ¤í¬ ì¬ì„¤ê³„
4. **ì‹ í˜¸ < 5/day**: ì„ê³„ê°’ ì¡°ì •

### ë¹„ìƒ ì •ì§€ ì¡°ê±´
- Risk of Ruin > 30% ì‹œ ê±°ë˜ ì¤‘ë‹¨
- ìƒì¡´í™•ë¥  < 80% ì‹œ ì „ëµ ì¬ê²€í† 
- ì—°ì† ì†ì‹¤ > ì‹œë®¬ë ˆì´ì…˜ 99% ì‹ ë¢°êµ¬ê°„
- ì¼ì¼ ì†ì‹¤ > ìµœì í™”ëœ í•œê³„
- ì‹œìŠ¤í…œ ì˜¤ë¥˜ 3íšŒ ì´ìƒ ì‹œ ì ê²€

### ê³„ì¢Œ ë³´í˜¸
- ì¼ì¼ ìµœëŒ€ ì†ì‹¤: ìµœì í™”ëœ ê°’
- ìµœëŒ€ ë™ì‹œ í¬ì§€ì…˜: 3-4ê°œ
- ì—°ì† ì†ì‹¤ í•œê³„: ì‹œë®¬ë ˆì´ì…˜ 99% ì‹ ë¢°êµ¬ê°„

### í¬ì§€ì…˜ë³„
- Stop Loss: 0.5-1.0 * ATR (ìµœì í™”)
- Take Profit: 1.5-2.5 * ATR (ìµœì í™”)
- Time Stop: 1-3ì‹œê°„ (ìµœì í™”)

---

## ğŸ”§ ë„êµ¬ ë° í™˜ê²½

### ê°œë°œ í™˜ê²½
- Python 3.10+
- TensorFlow/PyTorch
- Pandas/NumPy
- Optuna
- Backtrader/Vectorbt

### ë°ì´í„° ê´€ë¦¬
- PostgreSQL/TimescaleDB
- Redis (ì‹¤ì‹œê°„ ìºì‹œ)
- S3 (ë°±ì—…)

### ëª¨ë‹ˆí„°ë§
- Grafana dashboards
- Slack alerts
- Performance logs

---

## ğŸ’€ ë™ì  ë¦¬ìŠ¤í¬ ì „ëµ í•µì‹¬ ìš”ì•½

**"Survive to Thrive"**
- ê³ ì •ëœ ë¦¬ìŠ¤í¬ê°€ ì•„ë‹Œ ì‹œì¥ ì ì‘í˜• ìµœì í™”
- ìƒì¡´í™•ë¥  90% ì´ìƒ ìœ ì§€í•˜ë©° ìµœëŒ€ ìˆ˜ìµ ì¶”êµ¬
- Walk-Forwardë§ˆë‹¤ ë¦¬ìŠ¤í¬-ë ˆë²„ë¦¬ì§€ ì¬ê³„ì‚°
- ì‹œì¥ ìƒíƒœì— ë”°ë¥¸ ìë™ ìŠ¤ì¼€ì¼ë§

**í•µì‹¬ ë³´í˜¸ ì¥ì¹˜**
1. 2ë‹¨ê³„ ë¦¬ìŠ¤í¬-ë ˆë²„ë¦¬ì§€ ìµœì í™” (MC-Kelly â†’ Bayesian)
2. Wilson interval ê¸°ë°˜ RoR ê³„ì‚° (ì†Œí‘œë³¸ í¸í–¥ ì™„í™”)
3. ë”ë¸” ë ˆì§ ëª¨ë¸ (EWMA spread 50í‹± Ã— 1.8 = High)
4. ë°ì´í„° ëˆ„ìˆ˜ ìë™ ê²€ì¦ ì‹œìŠ¤í…œ

**ë™ì  ì¡°ì • ê·œì¹™**
1. ë§¤ Walk-Forward í›„ ìµœì ê°’ ì¬ê³„ì‚° (8-10íšŒ ìˆ˜ë ´)
2. ìƒì¡´í™•ë¥  < 90% ì‹œ ì¦‰ì‹œ ì¬ìµœì í™”
3. 15ì´ˆë§ˆë‹¤ Spread Regime ì²´í¬ (50í‹± EWMA ê¸°ì¤€)
4. DD ìˆ˜ì¤€ë³„ ë‹¨ê³„ì  ë¦¬ìŠ¤í¬ ì¶•ì†Œ

**ì‹¤ì œ ìš´ì˜ ì˜ˆì‹œ**
- ì €ë³€ë™ + Low DD: Risk 1.2%, Lev 10Ã—
- ì •ìƒ ì‹œì¥: Risk 1.0%, Lev 8Ã—
- ê³ ë³€ë™ or High DD: Risk 0.6%, Lev 5Ã—
- ë¡¤ì˜¤ë²„ ê¸°ê°„: Spread Ã— 1.3 ì ìš©

ì´ ì „ëµì€ **ìƒì¡´ì´ ìµœìš°ì„ **ì…ë‹ˆë‹¤.
íŒŒì‚°í•˜ì§€ ì•Šê³  ê¾¸ì¤€íˆ ì„±ì¥í•˜ëŠ” ê²ƒì´ í•µì‹¬ì…ë‹ˆë‹¤.

---

## âš ï¸ ìµœì¢… ê²½ê³ 

**ì´ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•˜ê¸° ì „ì— ë°˜ë“œì‹œ ì´í•´í•˜ì„¸ìš”:**
1. ì „ì²´ íˆ¬ìê¸ˆì„ ìƒì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤
2. ë ˆë²„ë¦¬ì§€ëŠ” ì†ì‹¤ì„ í¬ê²Œ ì¦í­ì‹œí‚µë‹ˆë‹¤
3. ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ëŠ” ì‹¤ì œ ê±°ë˜ì™€ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤
4. ì‹¬ë¦¬ì  ì••ë°•ì„ ê²¬ë”œ ì¤€ë¹„ê°€ í•„ìš”í•©ë‹ˆë‹¤
5. ì¶©ë¶„í•œ í…ŒìŠ¤íŠ¸ ì—†ì´ ì‹¤ê±°ë˜í•˜ì§€ ë§ˆì„¸ìš”

**íˆ¬ìëŠ” ê°œì¸ì˜ ì±…ì„ì…ë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì€ íˆ¬ì ì¡°ì–¸ì´ ì•„ë‹™ë‹ˆë‹¤.**
